# -*- coding: utf-8 -*-
"""animeclassificationvshumanclassification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tu1-gWHLng1OCrELbzSzvX8Th5NMh-Cu
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import math
import matplotlib.pyplot as plt
# %matplotlib inline
from statistics import mean
import datetime
# %tensorflow_version 2.x
from sklearn.model_selection import *
from sklearn.linear_model import *
from sklearn.naive_bayes import *
from sklearn.tree import *
import tensorflow as tf
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from google.colab import drive
from shutil import copyfile
import os
from tensorflow.keras import *
from keras.preprocessing.image import load_img ,img_to_array

x = np.array(np.repeat(0, 1000))
y = np.array(np.repeat(1, 1000))
x
label =np.concatenate((x,y))
drive.mount('/content/drive')
!cp '/content/drive/MyDrive/data3.zip' '/content'
! unzip data3.zip
directory = '/content/datapog'

height = 64
width =64
batch_size=32
data_train_gan = tf.keras.preprocessing.image_dataset_from_directory(
  directory,
  labels=list(label),
  validation_split=0.2,
  subset="training",
  seed=123,
  image_size=(height, width),
  batch_size=batch_size)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
  directory,
  labels=list(label),
	validation_split=0.2,
	subset="validation",
	seed=123,
	image_size=(height, width),
  batch_size=batch_size)

# normalization_layer = layers.experimental.preprocessing.Rescaling(1./255,input_shape=(64, 64, 3))
# normalized_ds = data_train_gan.map(lambda x, y: (normalization_layer(x), y))
# image_batch, labels_batch = next(iter(normalized_ds))
# first_image = image_batch[0]
# # Notice the pixels values are now in `[0,1]`.
# print(np.min(first_image), np.max(first_image))
# cnn.add(tf.keras.layers.Activation('sigmoid'))
# cnn.add(tf.keras.layers.MaxPool2D(pool_size=(1,1),strides=(1,1)))
# cnn.add(tf.keras.layers.Conv2D(32,padding="valid",strides=(1,1),kernel_size=(5,5),activation='tanh'))
#flatten 
  # layers.experimental.preprocessing.RandomRotation(0.1),
  # layers.experimental.preprocessing.RandomZoom(0.1),

# cnn=tf.keras.models.Sequential()
# cnn.add(tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(64, 64, 3)))
# cnn.add(tf.keras.layers.Conv2D(6,padding="valid",strides=(1,1),kernel_size=(4,4),activation='relu',kernel_initializer='he_normal'))
# cnn.add(tf.keras.layers.AveragePooling2D())
# cnn.add(tf.keras.layers.Activation('relu'))
# cnn.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))
# cnn.add(tf.keras.layers.Conv2D(16,padding="valid",strides=(1,1),kernel_size=(4,4),kernel_initializer='he_normal',activation='relu'))
# cnn.add(tf.keras.layers.Flatten())
# cnn.add(tf.keras.layers.Dense(units=64,activation='relu',input_shape=(64, 64, 3)))
# cnn.add(tf.keras.layers.Dense(units=32,activation='relu'))
# cnn.add(tf.keras.layers.Dense(units=3, activation='softmax'))
# cnn.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
# cnn.summary()

cnn = Sequential([
  layers.experimental.preprocessing.RandomFlip("horizontal", input_shape=(height, width, 3)),
  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(64, 64, 3)),
  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(8, 3, padding='same', activation='tanh'),
  layers.MaxPooling2D(),
  layers.Dropout(0.5),
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(units=32,activation='relu'),
  layers.Dense(units=3, activation='sigmoid')
])
cnn.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
cnn.summary()

hist = cnn.fit(data_train_gan, validation_data=val_ds, epochs=30)

acc = hist.history['accuracy']
val_acc = hist.history['val_accuracy']

loss = hist.history['loss']
val_loss = hist.history['val_loss']

epochs_range = range(30)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

import PIL
import PIL.Image
import glob
import tkinter
from urllib.request import urlopen
import base64
import requests

print("Now link an image that is preferably square and encompasses only the face from imgur or somewhere else, something like this:")
from IPython.display import Image, display
display(Image('/content/datapog/data/10.png'))
print("or")
display(Image('/content/datapog/data/68577.png'))

from PIL import Image
import cv2
url = input('Enter your link: ')
# url='https://i.imgur.com/cPuQbRj.png'
# url='https://i.imgur.com/Lbqxici.png'
im = Image.open(requests.get(url, stream=True).raw)
img = im.resize((64, 64))
display(img)
img = cv2.cvtColor(np.float32(img), cv2.COLOR_BGRA2BGR)


img_array = tf.keras.preprocessing.image.img_to_array(img)
img_array = tf.expand_dims(img_array, 0) # Create a batch
# print(img_array)

predictions = cnn.predict(img_array)
score = np.argmax(predictions[0])

# print(score)
# print(predictions)
if score==0:
  print("This picture is most likely the face of a cartoon/anime character")
else:
  print("This picture is most likely the face of a real human")

